{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff40484-c7b2-4922-9499-1786e990cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (4.13.4)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.12/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (3.12.13)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (2.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.11.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (4.24.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jovyan/.local/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached chromadb-1.0.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
      "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Using cached transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "Using cached build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached langsmith-0.4.14-py3-none-any.whl (373 kB)\n",
      "Using cached mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "Using cached opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Using cached orjson-3.11.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Using cached httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "Using cached uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: pypika, nvidia-cusparselt-cu12, mpmath, flatbuffers, durationpy, websockets, uvloop, uvicorn, triton, threadpoolctl, tenacity, sympy, shellingham, scipy, safetensors, regex, python-dotenv, pyproject_hooks, pybase64, pyasn1, protobuf, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, mypy-extensions, mmh3, mdurl, marshmallow, joblib, humanfriendly, httpx-sse, httptools, hf-xet, grpcio, fsspec, filelock, cachetools, bcrypt, backoff, watchfiles, typing-inspect, scikit-learn, rsa, requests-toolbelt, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, markdown-it-py, huggingface-hub, googleapis-common-protos, coloredlogs, build, tokenizers, rich, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, nvidia-cusolver-cu12, langsmith, google-auth, dataclasses-json, typer, transformers, torch, opentelemetry-sdk, langchain-core, kubernetes, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain, chromadb, langchain_community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87/87\u001b[0m [langchain_community]ommunity]ansformers]ntions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 cachetools-5.5.2 chromadb-1.0.16 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.7.0 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 hf-xet-1.1.7 httptools-0.6.4 httpx-sse-0.4.1 huggingface-hub-0.34.4 humanfriendly-10.0 joblib-1.5.1 kubernetes-33.1.0 langchain-0.3.27 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langchain_community-0.3.27 langsmith-0.4.14 markdown-it-py-4.0.0 marshmallow-3.26.1 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 mypy-extensions-1.1.0 networkx-3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.2 posthog-5.4.0 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-settings-2.10.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.1 regex-2025.7.34 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.1.0 rsa-4.9.1 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-5.1.0 shellingham-1.5.4 sympy-1.14.0 tenacity-9.1.2 threadpoolctl-3.6.0 tokenizers-0.21.4 torch-2.8.0 transformers-4.55.0 triton-3.4.0 typer-0.16.0 typing-inspect-0.9.0 uvicorn-0.35.0 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1\n",
      "Collecting lxml\n",
      "  Using cached lxml-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Using cached lxml-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community beautifulsoup4 chromadb sentence-transformers\n",
    "!pip install -U lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5820302a-ef18-456a-8954-437fdef61c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "from pathlib import Path\n",
    "import re, html\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from IPython.display import Markdown, display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b2d2a7-c669-423d-af05-612493053b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- injeta CSS uma única vez ---\n",
    "_BLACK_CSS_INJECTED = False\n",
    "# padrões (bloco e inline)\n",
    "_RE_FENCE_TRIPLE_BACKTICKS = re.compile(r\"```(.*?)```\", flags=re.DOTALL)\n",
    "_RE_FENCE_TRIPLE_QUOTES    = re.compile(r\"'''(.*?)'''\", flags=re.DOTALL)\n",
    "_RE_INLINE_BACKTICK        = re.compile(r\"`([^`]+)`\")\n",
    "# aspas simples com cuidado p/ não pegar apóstrofos em palavras\n",
    "_RE_INLINE_SINGLE_QUOTE    = re.compile(r\"(?<!\\\\w)'([^'\\\\n]+)'(?!\\\\w)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbccfe4-1032-4dc1-ba1d-0f607882f496",
   "metadata": {},
   "source": [
    "Criando os embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d87144-3f6e-4180-9ace-4c6b814d7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hf_embeddings(\n",
    "    model_name: str = \"intfloat/multilingual-e5-small\",\n",
    "    device: str = \"cpu\",\n",
    "    normalize_embeddings: bool = True,\n",
    "    **kwargs: Any,\n",
    ") -> HuggingFaceEmbeddings:\n",
    "    \"\"\"\n",
    "    Cria um objeto HuggingFaceEmbeddings compatível com o índice salvo.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    model_name : str, opcional\n",
    "        Nome do modelo de embeddings (ex.: \"intfloat/multilingual-e5-small\").\n",
    "    device : str, opcional\n",
    "        Dispositivo: \"cpu\" ou \"cuda\".\n",
    "    normalize_embeddings : bool, opcional\n",
    "        Se True, normaliza os vetores (útil para similaridade de cosseno).\n",
    "    **kwargs : Any\n",
    "        Pass-through para HuggingFaceEmbeddings (ex.: model_kwargs, encode_kwargs).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    HuggingFaceEmbeddings\n",
    "        Instância configurada de embeddings.\n",
    "    \"\"\"\n",
    "    model_kwargs = kwargs.pop(\"model_kwargs\", {\"device\": device})\n",
    "    encode_kwargs = kwargs.pop(\"encode_kwargs\", {\"normalize_embeddings\": normalize_embeddings})\n",
    "    print(f\" Carregando embeddings '{model_name}' em '{device}' (normalize={normalize_embeddings})\")\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c48e8-24d5-41bb-b3f1-90fe034cb8ec",
   "metadata": {},
   "source": [
    "Função para carregar índice Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d0dc38-6819-4e95-a25e-9939c6a633e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_index(\n",
    "    embeddings: HuggingFaceEmbeddings,\n",
    "    persist_directory: str,\n",
    ") -> Chroma:\n",
    "    \"\"\"\n",
    "    Carrega um índice vetorial Chroma previamente persistido em disco e informa contagem.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    embeddings : HuggingFaceEmbeddings\n",
    "        Objeto de embeddings *compatível* com o usado na criação do índice.\n",
    "    persist_directory : str\n",
    "        Caminho do diretório onde o índice foi salvo.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    Chroma\n",
    "        Instância do vetor store pronta para uso (busca/RAG).\n",
    "    \"\"\"\n",
    "    p = Path(persist_directory)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"O diretório '{persist_directory}' não existe. Crie o índice primeiro (notebook de guardar).\"\n",
    "        )\n",
    "\n",
    "    print(f\" 3. Carregando índice Chroma de '{persist_directory}' ...\")\n",
    "    vs = Chroma(\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "    )\n",
    "    # Contagem de itens (API interna do cliente do Chroma)\n",
    "    try:\n",
    "        n_items = vs._collection.count()  # type: ignore[attr-defined]\n",
    "        print(f\"   Coleção: '{vs._collection.name}' | Itens: {n_items}\")  # type: ignore[attr-defined]\n",
    "    except Exception:\n",
    "        print(\"   (Não foi possível obter a contagem via _collection; prosseguindo mesmo assim)\")\n",
    "\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365388a-99b1-40d3-b910-b9a91aba0fcd",
   "metadata": {},
   "source": [
    "Função para criar o retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f091b2aa-8c4a-410e-bf62-3c37af5fb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retriever(\n",
    "    vectorstore: Chroma,\n",
    "    k: int = 4,\n",
    "    score_threshold: Optional[float] = None,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Constrói um retriever para busca por similaridade no índice carregado.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    vectorstore : Chroma\n",
    "        Banco vetorial Chroma carregado.\n",
    "    k : int, opcional\n",
    "        Número de chunks a recuperar por consulta.\n",
    "    score_threshold : float, opcional\n",
    "        Limiar mínimo de score (quando suportado).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    BaseRetriever\n",
    "        Retriever compatível com LangChain, pronto para compor a cadeia de RAG.\n",
    "    \"\"\"\n",
    "    if score_threshold is None:\n",
    "        print(f\" 4. Criando retriever (k={k}) ...\")\n",
    "        return vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    print(f\" 4. Criando retriever (k={k}, score_threshold={score_threshold}) ...\")\n",
    "    return vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": k, \"score_threshold\": score_threshold},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527e5ac3-a254-4465-b6ba-958de5f3309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_brazilian_prompt() -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Prompt em PT-BR para respostas didáticas com uso de contexto.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    PromptTemplate\n",
    "        Template com variáveis: \"context\" e \"question\".\n",
    "    \"\"\"\n",
    "    template = (\n",
    "        \"Você é um assistente ESTRITAMENTE limitado à documentação do Python abaixo.\\n\"\n",
    "        \"REGRAS OBRIGATÓRIAS:\\n\"\n",
    "        \"1) Responda SOMENTE usando informações presentes no CONTEXTO.\\n\"\n",
    "        \"2) Se a resposta NÃO estiver claramente no contexto, diga apenas:\\n\"\n",
    "        \"   \\\"Não encontrei isso na documentação que tenho aqui.\\\"\\n\"\n",
    "        \"3) Se a pergunta for fora do tema Python, responda:\\n\"\n",
    "        \"   \\\"Fora de escopo: só posso responder sobre Python com base nos trechos fornecidos.\\\"\\n\"\n",
    "        \"4) Não use conhecimento prévio. Não invente. Não pesquise fora.\\n\"\n",
    "        \"\\n=== CONTEXTO ===\\n{context}\\n=== FIM DO CONTEXTO ===\\n\"\n",
    "        \"Pergunta (interprete sempre no contexto de Python): {question}\\n\"\n",
    "    )\n",
    "    return PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05772b32-6703-4744-990a-d59bbaf1a4d1",
   "metadata": {},
   "source": [
    "Função para criar LLM do Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4758445e-c3af-457e-b129-54cb40392fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ollama_llm(\n",
    "    model: str = \"llama3.2:3b-instruct-q4_K_M\",\n",
    "    temperature: float = 0.0,\n",
    "    **kwargs: Any,\n",
    ") -> Ollama:\n",
    "    \"\"\"\n",
    "    Prepara o LLM do Ollama para uso no RAG.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    model : str, opcional\n",
    "        Nome do modelo disponível no Ollama (`ollama list`).\n",
    "    temperature : float, opcional\n",
    "        Temperatura de amostragem.\n",
    "    **kwargs : Any\n",
    "        Parâmetros extras para `Ollama` (ex.: base_url, num_ctx).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    Ollama\n",
    "        Instância do LLM configurada.\n",
    "    \"\"\"\n",
    "    print(f\" 5. Preparando LLM Ollama (model={model}, temperature={temperature}) ...\")\n",
    "    return Ollama(model=model, temperature=temperature, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03be8b5-8fc0-456e-bbb2-81ab99984a8a",
   "metadata": {},
   "source": [
    "Função para montar cadeia RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f678b562-bc41-4bd1-9600-6f6cc6633cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_qa_chain(\n",
    "    llm: Ollama,\n",
    "    retriever: Any,\n",
    "    prompt: PromptTemplate,\n",
    "    chain_type: str = \"stuff\",\n",
    "    return_sources: bool = True,\n",
    ") -> RetrievalQA:\n",
    "    \"\"\"\n",
    "    Monta a cadeia RAG (Retriever + Prompt + LLM) para responder perguntas com contexto.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    llm : Ollama\n",
    "        Modelo de linguagem preparado.\n",
    "    retriever : BaseRetriever\n",
    "        Mecanismo de recuperação a partir do Chroma.\n",
    "    prompt : PromptTemplate\n",
    "        Template com variáveis \"context\" e \"question\".\n",
    "    chain_type : str, opcional\n",
    "        Tipo da cadeia (\"stuff\", \"map_reduce\", \"refine\").\n",
    "    return_sources : bool, opcional\n",
    "        Se True, retorna documentos-fonte.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    RetrievalQA\n",
    "        Cadeia pronta para executar perguntas.\n",
    "    \"\"\"\n",
    "    print(\" 6. Montando cadeia de RAG ...\")\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=chain_type,\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=return_sources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bef12-0a73-4502-bb3e-015783b063d3",
   "metadata": {},
   "source": [
    "formatando a saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb922607-54ce-46e1-9b99-ab1ad94b35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sources(source_documents: Optional[Sequence[Any]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Converte Documents de fonte em strings amigáveis (caminho + score quando disponível).\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    source_documents : Sequence[Document] | None\n",
    "        Documentos retornados pelo retriever/chain.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    List[str]\n",
    "        Lista de descrições de fonte.\n",
    "    \"\"\"\n",
    "    items: List[str] = []\n",
    "    for doc in source_documents or []:\n",
    "        meta = getattr(doc, \"metadata\", {}) or {}\n",
    "        origem = meta.get(\"source\") or meta.get(\"file_path\") or str(meta)\n",
    "        score = meta.get(\"score\")\n",
    "        if score is not None:\n",
    "            origem = f\"{origem} (score={score})\"\n",
    "        items.append(origem)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f829ba91-f33d-4fd6-a479-36336f936659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_black_code_css() -> None:\n",
    "    \"\"\"Injeta CSS para caixas de código com fundo preto e texto branco (inline e bloco).\"\"\"\n",
    "    global _BLACK_CSS_INJECTED\n",
    "    if _BLACK_CSS_INJECTED:\n",
    "        return\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "      /* Inline \"pílula\" */\n",
    "      .codechip {\n",
    "        display: inline-block !important;\n",
    "        background: #000 !important;\n",
    "        color: #fff !important;\n",
    "        padding: 0 6px !important;\n",
    "        border-radius: 6px !important;\n",
    "        line-height: 1.4 !important;\n",
    "        vertical-align: baseline !important;\n",
    "        font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
    "      }\n",
    "      .codechip code {\n",
    "        background: transparent !important;\n",
    "        color: inherit !important;\n",
    "        padding: 0 !important;\n",
    "      }\n",
    "\n",
    "      /* Bloco */\n",
    "      .codeblock {\n",
    "        display: block !important;\n",
    "        background: #000 !important;\n",
    "        color: #fff !important;\n",
    "        padding: 10px 12px !important;\n",
    "        border-radius: 8px !important;\n",
    "        white-space: pre-wrap !important;\n",
    "        overflow: auto !important;\n",
    "        font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace !important;\n",
    "        margin: .6em 0 !important;\n",
    "      }\n",
    "      .codeblock code {\n",
    "        background: transparent !important;\n",
    "        color: inherit !important;\n",
    "        padding: 0 !important;\n",
    "      }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(css))\n",
    "    _BLACK_CSS_INJECTED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e2d97-2aa6-4765-91c6-6e7ce2fa0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wrap_block(code: str) -> str:\n",
    "    \"\"\"Envolve como bloco (caixa preta maior).\"\"\"\n",
    "    return f\"<pre class='codeblock'><code>{html.escape(code.strip())}</code></pre>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c7ab62-4e5c-4155-b739-b86636d477f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wrap_inline(code: str) -> str:\n",
    "    \"\"\"Envolve como pílula inline (apenas um pouco maior que o conteúdo).\"\"\"\n",
    "    return f\"<span class='codechip'><code>{html.escape(code.strip())}</code></span>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24f813c-96d2-4e61-871d-d9f584a09b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_code_blocks_black(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converte:\n",
    "      - ```bloco```,  '''bloco'''  → bloco com fundo preto\n",
    "      - `inline`, 'inline'          → pílula inline com fundo preto\n",
    "    Garante contraste (texto branco) e evita CSS do tema sobrescrever.\n",
    "    \"\"\"\n",
    "    placeholders: List[str] = []\n",
    "\n",
    "    def sub_block(pattern: re.Pattern, s: str) -> str:\n",
    "        def push(m: re.Match) -> str:\n",
    "            placeholders.append(_wrap_block(m.group(1)))\n",
    "            return f\"@@CODE{len(placeholders)-1}@@\"\n",
    "        return pattern.sub(push, s)\n",
    "\n",
    "    def sub_inline(pattern: re.Pattern, s: str) -> str:\n",
    "        def push(m: re.Match) -> str:\n",
    "            placeholders.append(_wrap_inline(m.group(1)))\n",
    "            return f\"@@CODE{len(placeholders)-1}@@\"\n",
    "        return pattern.sub(push, s)\n",
    "\n",
    "    # 1) blocos primeiro\n",
    "    tmp = sub_block(_RE_FENCE_TRIPLE_BACKTICKS, text)\n",
    "    tmp = sub_block(_RE_FENCE_TRIPLE_QUOTES,    tmp)\n",
    "    # 2) inlines depois\n",
    "    tmp = sub_inline(_RE_INLINE_BACKTICK,       tmp)\n",
    "    tmp = sub_inline(_RE_INLINE_SINGLE_QUOTE,   tmp)\n",
    "\n",
    "    # 3) escapa tudo que sobrou (texto comum), para não virar HTML acidental\n",
    "    safe = html.escape(tmp)\n",
    "\n",
    "    # 4) recoloca os HTML reais\n",
    "    for i, html_block in enumerate(placeholders):\n",
    "        token = f\"@@CODE{i}@@\"\n",
    "        safe = safe.replace(html.escape(token), html_block).replace(token, html_block)\n",
    "\n",
    "    return safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafe40e3-c13a-4dc5-b314-2d60b80b6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(\n",
    "    chain: RetrievalQA,\n",
    "    question: str,\n",
    "    show_sources: bool = True,\n",
    "    retriever_for_guard: Optional[Any] = None,\n",
    "    hide_sources_when_empty: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Versão estrita: se não houver docs relevantes, não deixa o LLM responder.\n",
    "    Só imprime 'Fontes' quando existir pelo menos 1 fonte (ou quando hide_sources_when_empty=False).\n",
    "    \"\"\"\n",
    "    print(f\" 7. Pergunta: {question}\")\n",
    "\n",
    "    # 0) Guarda de contexto: consulta o retriever antes\n",
    "    if retriever_for_guard is not None:\n",
    "        pre_docs = retriever_for_guard.get_relevant_documents(question)\n",
    "        if not pre_docs:  # nada acima do score_threshold\n",
    "            ensure_black_code_css()\n",
    "            msg = (\n",
    "                \"Fora de escopo ou não encontrado no contexto.\\n\"\n",
    "                \"Não encontrei isso na documentação que tenho aqui.\"\n",
    "            )\n",
    "            answer_html = format_code_blocks_black(msg)\n",
    "            display(HTML(answer_html))\n",
    "\n",
    "            # Não imprime seção de fontes quando não há nenhuma\n",
    "            if show_sources and not hide_sources_when_empty:\n",
    "                print(\"\\n---\\n Fontes: (nenhuma)\")\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer_html,\n",
    "                \"sources\": [],\n",
    "                \"raw\": {\"result\": msg, \"source_documents\": []},\n",
    "            }\n",
    "\n",
    "    # 1) Executa a chain normalmente\n",
    "    resp = chain(question)\n",
    "\n",
    "    # 2) Renderização\n",
    "    ensure_black_code_css()\n",
    "    answer_html = format_code_blocks_black(resp.get(\"result\", \"\"))\n",
    "    print(\"\\n Resposta:\\n\")\n",
    "    display(HTML(answer_html))\n",
    "\n",
    "    # 3) Fontes (imprime só se houver)\n",
    "    srcs: List[str] = format_sources(resp.get(\"source_documents\", []))\n",
    "\n",
    "    if show_sources:\n",
    "        if srcs:\n",
    "            print(\"\\n---\\n Fontes:\")\n",
    "            for i, s in enumerate(srcs, 1):\n",
    "                print(f\"[{i}] {s}\")\n",
    "        elif not hide_sources_when_empty:\n",
    "            print(\"\\n---\\n Fontes: (nenhuma)\")\n",
    "\n",
    "    return {\"answer\": answer_html, \"sources\": srcs, \"raw\": resp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c55decb2-2cd8-48de-a6a9-d671f16d6d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Carregando embeddings 'intfloat/multilingual-e5-small' em 'cpu' (normalize=True)\n",
      " 3. Carregando índice Chroma de './chroma_db_python_iniciante' ...\n",
      "   Coleção: 'langchain' | Itens: 9293\n",
      " 4. Criando retriever (k=4, score_threshold=0.25) ...\n",
      " 5. Preparando LLM Ollama (model=llama3.2:3b-instruct-q4_K_M, temperature=0.0) ...\n",
      " 6. Montando cadeia de RAG ...\n",
      " 7. Pergunta: defina o que é uma classe e de exemplos\n",
      "\n",
      " Resposta:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Uma classe em Python é um modelo para criação de objetos definidos pelo usuário. Ela define métodos que operam sobre instâncias da classe, e também pode conter variáveis de classe que são modificadas apenas no nível da classe.\n",
       "\n",
       "Exemplos:\n",
       "\n",
       "<pre class='codeblock'><code>python\n",
       "class Carro:\n",
       "    cor = &quot;Preto&quot;\n",
       "    velocidade = 0\n",
       "\n",
       "    def __init__(self, marca, modelo):\n",
       "        self.marca = marca\n",
       "        self.modelo = modelo\n",
       "\n",
       "    def acelerar(self):\n",
       "        self.velocidade += 10\n",
       "\n",
       "    def get_velocidade(self):\n",
       "        return self.velocidade\n",
       "\n",
       "# Criando um objeto carro\n",
       "carro1 = Carro(&quot;Ford&quot;, &quot;F-150&quot;)\n",
       "print(carro1.get_velocidade())  # Saída: 0\n",
       "\n",
       "# Acelerando o carro\n",
       "carro1.acelerar()\n",
       "print(carro1.get_velocidade())  # Saída: 10\n",
       "\n",
       "# Modificando a cor do carro (variável de classe)\n",
       "Carro.cor = &quot;Azul&quot;\n",
       "print(Carro.cor)  # Saída: Azul</code></pre>\n",
       "\n",
       "Nesse exemplo, <span class='codechip'><code>Carro</code></span> é uma classe que define um método <span class='codechip'><code>__init__</code></span> para inicializar os atributos da classe (<span class='codechip'><code>marca</code></span> e <span class='codechip'><code>modelo</code></span>), um método <span class='codechip'><code>acelerar</code></span> para aumentar a velocidade do carro, e uma variável de classe <span class='codechip'><code>cor</code></span>. A classe também tem um atributo <span class='codechip'><code>velocidade</code></span> que é inicializado com 0."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      " Fontes:\n",
      "[1] data/python-3.13-docs-html/reference/datamodel.html\n",
      "[2] data/python-3.13-docs-html/reference/compound_stmts.html\n",
      "[3] data/python-3.13-docs-html/reference/executionmodel.html\n",
      "[4] data/python-3.13-docs-html/glossary.html\n"
     ]
    }
   ],
   "source": [
    "# === Parâmetros ===\n",
    "PERSIST_DIR = \"./chroma_db_python_iniciante\"      # mesmo diretório usado no notebook de guardar\n",
    "EMBEDDINGS_MODEL = \"intfloat/multilingual-e5-small\"\n",
    "DEVICE = \"cpu\"                                     # ou \"cuda\"\n",
    "NORMALIZE = True\n",
    "K = 4                                              # número de chunks retornados\n",
    "OLLAMA_MODEL = \"llama3.2:3b-instruct-q4_K_M\"\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# === Pipeline ===\n",
    "emb = build_hf_embeddings(\n",
    "    model_name=EMBEDDINGS_MODEL,\n",
    "    device=DEVICE,\n",
    "    normalize_embeddings=NORMALIZE\n",
    ")\n",
    "\n",
    "vs = load_chroma_index(\n",
    "    embeddings=emb,\n",
    "    persist_directory=PERSIST_DIR\n",
    ")\n",
    "\n",
    "retriever = build_retriever(\n",
    "    vectorstore=vs,\n",
    "    k=K,\n",
    "    score_threshold=0.25  # ou por exemplo 0.2, se quiser filtrar\n",
    ")\n",
    "\n",
    "prompt = default_brazilian_prompt()\n",
    "llm = build_ollama_llm(model=OLLAMA_MODEL, temperature=TEMPERATURE)\n",
    "chain = build_retrieval_qa_chain(llm, retriever, prompt)\n",
    "\n",
    "# === Perguntar ===\n",
    "QUESTION = \"defina o que é uma classe e de exemplos\"\n",
    "result = ask(chain, QUESTION, show_sources=True, hide_sources_when_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39c39b-d411-45b2-965e-7e07b4c863a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
