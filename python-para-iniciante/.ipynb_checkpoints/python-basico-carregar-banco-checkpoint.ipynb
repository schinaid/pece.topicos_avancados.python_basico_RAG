{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ff40484-c7b2-4922-9499-1786e990cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: chromadb in /opt/conda/lib/python3.12/site-packages (1.0.16)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.12/site-packages (5.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /opt/conda/lib/python3.12/site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /opt/conda/lib/python3.12/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/conda/lib/python3.12/site-packages (from langchain) (0.4.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.12/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/conda/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (3.12.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (2.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.12/site-packages (from chromadb) (0.21.4)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/conda/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.12/site-packages (from chromadb) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /opt/conda/lib/python3.12/site-packages (from chromadb) (4.24.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.55.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/conda/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.31.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jovyan/.local/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.12/site-packages (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community beautifulsoup4 chromadb sentence-transformers\n",
    "!pip install -U lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5820302a-ef18-456a-8954-437fdef61c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0d87144-3f6e-4180-9ace-4c6b814d7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hf_embeddings(\n",
    "    model_name: str = \"intfloat/multilingual-e5-small\",\n",
    "    device: str = \"cpu\",\n",
    "    normalize_embeddings: bool = True,\n",
    "    **kwargs: Any,\n",
    ") -> HuggingFaceEmbeddings:\n",
    "    \"\"\"\n",
    "    Cria um objeto HuggingFaceEmbeddings compatível com o índice salvo.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    model_name : str, opcional\n",
    "        Nome do modelo de embeddings (ex.: \"intfloat/multilingual-e5-small\").\n",
    "    device : str, opcional\n",
    "        Dispositivo: \"cpu\" ou \"cuda\".\n",
    "    normalize_embeddings : bool, opcional\n",
    "        Se True, normaliza os vetores (útil para similaridade de cosseno).\n",
    "    **kwargs : Any\n",
    "        Pass-through para HuggingFaceEmbeddings (ex.: model_kwargs, encode_kwargs).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    HuggingFaceEmbeddings\n",
    "        Instância configurada de embeddings.\n",
    "    \"\"\"\n",
    "    model_kwargs = kwargs.pop(\"model_kwargs\", {\"device\": device})\n",
    "    encode_kwargs = kwargs.pop(\"encode_kwargs\", {\"normalize_embeddings\": normalize_embeddings})\n",
    "    print(f\" Carregando embeddings '{model_name}' em '{device}' (normalize={normalize_embeddings})\")\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        **kwargs,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86d0dc38-6819-4e95-a25e-9939c6a633e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_index(\n",
    "    embeddings: HuggingFaceEmbeddings,\n",
    "    persist_directory: str,\n",
    ") -> Chroma:\n",
    "    \"\"\"\n",
    "    Carrega um índice vetorial Chroma previamente persistido em disco e informa contagem.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    embeddings : HuggingFaceEmbeddings\n",
    "        Objeto de embeddings *compatível* com o usado na criação do índice.\n",
    "    persist_directory : str\n",
    "        Caminho do diretório onde o índice foi salvo.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    Chroma\n",
    "        Instância do vetor store pronta para uso (busca/RAG).\n",
    "    \"\"\"\n",
    "    p = Path(persist_directory)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"O diretório '{persist_directory}' não existe. Crie o índice primeiro (notebook de guardar).\"\n",
    "        )\n",
    "\n",
    "    print(f\" 3. Carregando índice Chroma de '{persist_directory}' ...\")\n",
    "    vs = Chroma(\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "    )\n",
    "    # Contagem de itens (API interna do cliente do Chroma)\n",
    "    try:\n",
    "        n_items = vs._collection.count()  # type: ignore[attr-defined]\n",
    "        print(f\"   Coleção: '{vs._collection.name}' | Itens: {n_items}\")  # type: ignore[attr-defined]\n",
    "    except Exception:\n",
    "        print(\"   (Não foi possível obter a contagem via _collection; prosseguindo mesmo assim)\")\n",
    "\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f091b2aa-8c4a-410e-bf62-3c37af5fb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retriever(\n",
    "    vectorstore: Chroma,\n",
    "    k: int = 4,\n",
    "    score_threshold: Optional[float] = None,\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Constrói um retriever para busca por similaridade no índice carregado.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    vectorstore : Chroma\n",
    "        Banco vetorial Chroma carregado.\n",
    "    k : int, opcional\n",
    "        Número de chunks a recuperar por consulta.\n",
    "    score_threshold : float, opcional\n",
    "        Limiar mínimo de score (quando suportado).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    BaseRetriever\n",
    "        Retriever compatível com LangChain, pronto para compor a cadeia de RAG.\n",
    "    \"\"\"\n",
    "    if score_threshold is None:\n",
    "        print(f\" 4. Criando retriever (k={k}) ...\")\n",
    "        return vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    print(f\" 4. Criando retriever (k={k}, score_threshold={score_threshold}) ...\")\n",
    "    return vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": k, \"score_threshold\": score_threshold},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "527e5ac3-a254-4465-b6ba-958de5f3309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_brazilian_prompt() -> PromptTemplate:\n",
    "    \"\"\"\n",
    "    Prompt em PT-BR para respostas didáticas com uso de contexto.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    PromptTemplate\n",
    "        Template com variáveis: \"context\" e \"question\".\n",
    "    \"\"\"\n",
    "    template = (\n",
    "        \"Use o contexto a seguir para responder à pergunta no final.\\n\"\n",
    "        \"Se você não souber, diga que não sabe — não invente.\\n\"\n",
    "        \"Responda em Português do Brasil, com clareza e exemplos passo a passo quando fizer sentido.\\n\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Pergunta: {question}\\n\"\n",
    "        \"Resposta útil:\"\n",
    "    )\n",
    "    return PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4758445e-c3af-457e-b129-54cb40392fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ollama_llm(\n",
    "    model: str = \"llama3.2:3b-instruct-q4_K_M\",\n",
    "    temperature: float = 0.0,\n",
    "    **kwargs: Any,\n",
    ") -> Ollama:\n",
    "    \"\"\"\n",
    "    Prepara o LLM do Ollama para uso no RAG.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    model : str, opcional\n",
    "        Nome do modelo disponível no Ollama (`ollama list`).\n",
    "    temperature : float, opcional\n",
    "        Temperatura de amostragem.\n",
    "    **kwargs : Any\n",
    "        Parâmetros extras para `Ollama` (ex.: base_url, num_ctx).\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    Ollama\n",
    "        Instância do LLM configurada.\n",
    "    \"\"\"\n",
    "    print(f\" 5. Preparando LLM Ollama (model={model}, temperature={temperature}) ...\")\n",
    "    return Ollama(model=model, temperature=temperature, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f678b562-bc41-4bd1-9600-6f6cc6633cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_qa_chain(\n",
    "    llm: Ollama,\n",
    "    retriever: Any,\n",
    "    prompt: PromptTemplate,\n",
    "    chain_type: str = \"stuff\",\n",
    "    return_sources: bool = True,\n",
    ") -> RetrievalQA:\n",
    "    \"\"\"\n",
    "    Monta a cadeia RAG (Retriever + Prompt + LLM) para responder perguntas com contexto.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    llm : Ollama\n",
    "        Modelo de linguagem preparado.\n",
    "    retriever : BaseRetriever\n",
    "        Mecanismo de recuperação a partir do Chroma.\n",
    "    prompt : PromptTemplate\n",
    "        Template com variáveis \"context\" e \"question\".\n",
    "    chain_type : str, opcional\n",
    "        Tipo da cadeia (\"stuff\", \"map_reduce\", \"refine\").\n",
    "    return_sources : bool, opcional\n",
    "        Se True, retorna documentos-fonte.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    RetrievalQA\n",
    "        Cadeia pronta para executar perguntas.\n",
    "    \"\"\"\n",
    "    print(\" 6. Montando cadeia de RAG ...\")\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=chain_type,\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=return_sources,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb922607-54ce-46e1-9b99-ab1ad94b35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sources(source_documents: Optional[Sequence[Any]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Converte Documents de fonte em strings amigáveis (caminho + score quando disponível).\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    source_documents : Sequence[Document] | None\n",
    "        Documentos retornados pelo retriever/chain.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    List[str]\n",
    "        Lista de descrições de fonte.\n",
    "    \"\"\"\n",
    "    items: List[str] = []\n",
    "    for doc in source_documents or []:\n",
    "        meta = getattr(doc, \"metadata\", {}) or {}\n",
    "        origem = meta.get(\"source\") or meta.get(\"file_path\") or str(meta)\n",
    "        score = meta.get(\"score\")\n",
    "        if score is not None:\n",
    "            origem = f\"{origem} (score={score})\"\n",
    "        items.append(origem)\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eafe40e3-c13a-4dc5-b314-2d60b80b6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(\n",
    "    chain: RetrievalQA,\n",
    "    question: str,\n",
    "    show_sources: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Executa uma pergunta na cadeia RAG e retorna resposta + fontes.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    chain : RetrievalQA\n",
    "        Cadeia construída por `build_retrieval_qa_chain`.\n",
    "    question : str\n",
    "        Pergunta do usuário.\n",
    "    show_sources : bool, opcional\n",
    "        Se True, imprime as fontes ao final.\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    dict\n",
    "        {\n",
    "          \"answer\": str,\n",
    "          \"sources\": List[str],\n",
    "          \"raw\": Any   # objeto bruto retornado pelo chain\n",
    "        }\n",
    "    \"\"\"\n",
    "    print(f\" 7. Pergunta: {question}\")\n",
    "    resp = chain(question)\n",
    "    answer = resp.get(\"result\", \"\")\n",
    "    srcs = format_sources(resp.get(\"source_documents\"))\n",
    "    print(\"\\n Resposta:\\n\", answer)\n",
    "    if show_sources:\n",
    "        print(\"\\n---\\n Fontes:\")\n",
    "        for i, s in enumerate(srcs, 1):\n",
    "            print(f\"[{i}] {s}\")\n",
    "    return {\"answer\": answer, \"sources\": srcs, \"raw\": resp}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c55decb2-2cd8-48de-a6a9-d671f16d6d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Carregando embeddings 'intfloat/multilingual-e5-small' em 'cpu' (normalize=True)\n",
      " 3. Carregando índice Chroma de './chroma_db_python_iniciante' ...\n",
      "   ➜ Coleção: 'langchain' | Itens: 9293\n",
      " 4. Criando retriever (k=4) ...\n",
      " 5. Preparando LLM Ollama (model=llama3.2:3b-instruct-q4_K_M, temperature=0.0) ...\n",
      " 6. Montando cadeia de RAG ...\n",
      " 7. Pergunta: Qual a recomendação de uso do venv na documentação do Python?\n",
      "\n",
      " Resposta:\n",
      " A recomendação de uso do `venv` é que ele deve ser usado para criar ambientes virtuais, como mencionado na versão 3.5 da documentação do Python. Isso significa que em vez de usar as ferramentas de empacotamento padrão, como o comando `python -m pip install`, você deve usar o comando `venv` para criar um ambiente virtual e instalar os módulos necessários.\n",
      "\n",
      "Por exemplo, se você quiser instalar o módulo `AlgumPacote`, você deve usar o comando:\n",
      "\n",
      "```bash\n",
      "python -m venv meuambiente\n",
      "source meuambiente/bin/activate\n",
      "pip install AlgumPacote\n",
      "```\n",
      "\n",
      "Ou, se você estiver usando um sistema operacional POSIX (como macOS ou Linux), você pode usar o comando:\n",
      "\n",
      "```bash\n",
      "python -m venv meuambiente\n",
      ". meuambiente/bin/activate\n",
      "pip install AlgumPacote\n",
      "```\n",
      "\n",
      "Essa é a recomendação de uso do `venv` na documentação do Python, que é criar ambientes virtuais usando o comando `venv` e ativar o ambiente virtual antes de instalar os módulos necessários.\n",
      "\n",
      "---\n",
      " Fontes:\n",
      "[1] data/python-3.13-docs-html/installing/index.html\n",
      "[2] data/python-3.13-docs-html/whatsnew/3.11.html\n",
      "[3] data/python-3.13-docs-html/contents.html\n",
      "[4] data/python-3.13-docs-html/whatsnew/3.8.html\n"
     ]
    }
   ],
   "source": [
    "# === Parâmetros ===\n",
    "PERSIST_DIR = \"./chroma_db_python_iniciante\"      # mesmo diretório usado no notebook de guardar\n",
    "EMBEDDINGS_MODEL = \"intfloat/multilingual-e5-small\"\n",
    "DEVICE = \"cpu\"                                     # ou \"cuda\"\n",
    "NORMALIZE = True\n",
    "K = 4                                              # número de chunks retornados\n",
    "OLLAMA_MODEL = \"llama3.2:3b-instruct-q4_K_M\"\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# === Pipeline ===\n",
    "emb = build_hf_embeddings(\n",
    "    model_name=EMBEDDINGS_MODEL,\n",
    "    device=DEVICE,\n",
    "    normalize_embeddings=NORMALIZE\n",
    ")\n",
    "\n",
    "vs = load_chroma_index(\n",
    "    embeddings=emb,\n",
    "    persist_directory=PERSIST_DIR\n",
    ")\n",
    "\n",
    "retriever = build_retriever(\n",
    "    vectorstore=vs,\n",
    "    k=K,\n",
    "    score_threshold=None  # ou por exemplo 0.2, se quiser filtrar\n",
    ")\n",
    "\n",
    "prompt = default_brazilian_prompt()\n",
    "llm = build_ollama_llm(model=OLLAMA_MODEL, temperature=TEMPERATURE)\n",
    "chain = build_retrieval_qa_chain(llm, retriever, prompt)\n",
    "\n",
    "# === Perguntar ===\n",
    "QUESTION = \"Qual a recomendação de uso do venv na documentação do Python?\"\n",
    "result = ask(chain, QUESTION, show_sources=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88abb2-35a3-4f45-bb4f-5b9a7d0fa3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46fe555b-5d5e-49e5-9bda-3f25d0d8f2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5806ec97-f8ea-4ccd-951e-b34ceec91085",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIRECTORY = \"chroma_db_python_iniciante\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11b51574-ac38-4d01-bb6f-55839ee5cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FASE 3: CONSTRUINDO A CADEIA DE RESPOSTAS (RAG) ---\n",
    "prompt_template = \"\"\"\n",
    "Use o contexto a seguir para responder à pergunta no final.\n",
    "Se você não sabe a resposta, apenas diga que não sabe, não tente inventar uma resposta.\n",
    "Responda em Português do Brasil. Lembre-se: você é um assistente de Python para iniciantes, então responda claramente, com diversos exemplos passo a passo.\n",
    "\n",
    "{context}\n",
    "\n",
    "Pergunta: {question}\n",
    "Resposta útil:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73af7a9e-5df7-4c97-9fdb-881e6566f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f82ffc4b-6eb1-46f8-97c4-3e47a7097ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesma configuração de embeddings do notebook original\n",
    "model_name = \"intfloat/multilingual-e5-small\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a61cd50-5c98-42c3-badf-2e1e98d4f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o vetorstore existente a partir do disco\n",
    "# IMPORTANTE: não passamos 'from_documents', apenas 'persist_directory'\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "195aa092-a00e-4415-b28a-d9534de56013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store carregado de chroma_db_python_iniciante\n",
      "Total de documentos/chunks (aprox.): 9293\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Vector store carregado de\", PERSIST_DIRECTORY)\n",
    "try:\n",
    "    # algumas versões expõem ._collection.count()\n",
    "    print(\"Total de documentos/chunks (aprox.):\", vectorstore._collection.count())\n",
    "except Exception:\n",
    "    # fallback: não quebra se a API mudar\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06eceea9-959a-4811-94de-15105404472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) LLM (Ollama) e Cadeia de Consulta (RetrievalQA)\n",
    "# Use o mesmo modelo que você utilizou antes\n",
    "llm = Ollama(model=\"llama3\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec4b6d78-c3a8-4e68-9c93-e810031cd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3529e9f2-b310-44bc-b5ed-a9a221b895cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",   # pode trocar para 'map_reduce' dependendo do seu caso\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f842764e-c6c0-4956-b2aa-1fc69693c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cadeia de consulta pronta!\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Cadeia de consulta pronta!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48fafd6a-0c0f-4775-bb70-60934feaecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Função utilitária para perguntar\n",
    "def perguntar(pergunta: str):\n",
    "    \"\"\"Executa a consulta no RAG já carregado e imprime resposta + fontes.\"\"\"\n",
    "    resp = qa_chain(pergunta)\n",
    "    print(\"\\n### Resposta:\\n\", resp['result'])\n",
    "    print(\"\\n---\\n### Fontes:\")\n",
    "    for i, doc in enumerate(resp.get('source_documents', []), start=1):\n",
    "        meta = doc.metadata if hasattr(doc, 'metadata') else {}\n",
    "        origem = meta.get('source') or meta.get('file_path') or str(meta)\n",
    "        score = meta.get('score')\n",
    "        print(f\"[{i}] {origem}\" + (f\" -> score: {score}\" if score is not None else \"\"))\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f7c7546-86ef-45d0-ab6a-c56a7d0ddafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Resposta:\n",
      " A pergunta é sobre a escritura de código mais aceita no Python, segundo a PEP (Python Enhancement Proposal).\n",
      "\n",
      "De acordo com as PEPs mencionadas anteriormente, não há uma PEP específica que defina a escritura de código mais aceita. No entanto, é comum usar a snake_case (ou underscore notation) para nomes de variáveis e funções em Python.\n",
      "\n",
      "A PEP 8, que é a PEP oficial sobre estilo de código em Python, recomenda usar a snake_case para nomes de variáveis e funções. A PEP 8 também sugere usar camelCase para nomes de classes e objetos, mas isso não é uma regra rígida.\n",
      "\n",
      "Portanto, a resposta mais aceita é usar a snake_case (ou underscore notation) para nomes de variáveis e funções em Python, como por exemplo: `my_variable_name` ou `calculate_total`.\n",
      "\n",
      "Lembre-se de que o importante é ser consistente em sua escritura de código e seguir as recomendações da PEP 8.\n",
      "\n",
      "---\n",
      "### Fontes:\n",
      "[1] data/python-3.13-docs-html/contents.html\n",
      "[2] data/python-3.13-docs-html/contents.html\n",
      "[3] data/python-3.13-docs-html/reference/datamodel.html\n",
      "[4] data/python-3.13-docs-html/whatsnew/3.12.html\n"
     ]
    }
   ],
   "source": [
    "_ = perguntar(\"qual a escrita de código mais aceita segundo a pep camel_case ou snake_case?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b2a5d-f01b-4b99-b135-31f45aa88980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
